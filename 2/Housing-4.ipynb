{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"end_to_end_project\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17606</th>\n",
       "      <td>-121.89</td>\n",
       "      <td>37.29</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>2.7042</td>\n",
       "      <td>286600.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18632</th>\n",
       "      <td>-121.93</td>\n",
       "      <td>37.05</td>\n",
       "      <td>14.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>6.4214</td>\n",
       "      <td>340600.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14650</th>\n",
       "      <td>-117.20</td>\n",
       "      <td>32.77</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>2.8621</td>\n",
       "      <td>196900.0</td>\n",
       "      <td>NEAR OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>-119.61</td>\n",
       "      <td>36.31</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1847.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>1.8839</td>\n",
       "      <td>46300.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3555</th>\n",
       "      <td>-118.59</td>\n",
       "      <td>34.23</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6592.0</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>4459.0</td>\n",
       "      <td>1463.0</td>\n",
       "      <td>3.0347</td>\n",
       "      <td>254500.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "17606    -121.89     37.29                38.0       1568.0           351.0   \n",
       "18632    -121.93     37.05                14.0        679.0           108.0   \n",
       "14650    -117.20     32.77                31.0       1952.0           471.0   \n",
       "3230     -119.61     36.31                25.0       1847.0           371.0   \n",
       "3555     -118.59     34.23                17.0       6592.0          1525.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \\\n",
       "17606       710.0       339.0         2.7042            286600.0   \n",
       "18632       306.0       113.0         6.4214            340600.0   \n",
       "14650       936.0       462.0         2.8621            196900.0   \n",
       "3230       1460.0       353.0         1.8839             46300.0   \n",
       "3555       4459.0      1463.0         3.0347            254500.0   \n",
       "\n",
       "      ocean_proximity  \n",
       "17606       <1H OCEAN  \n",
       "18632       <1H OCEAN  \n",
       "14650      NEAR OCEAN  \n",
       "3230           INLAND  \n",
       "3555        <1H OCEAN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set = pd.read_csv('./strat_train_set.csv', index_col=0)\n",
    "strat_train_set.head()\n",
    "# type(strat_train_set)\n",
    "# strat_train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.drop(\"median_house_value\", axis=1) # drop labels for training set\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 自定义转换器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# column index\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,\n",
    "                         bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sklearn.base.BaseEstimator](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base class for all estimators in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[sklearn.base.TransformerMixin](https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixin class for all transformers in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-121.89, 37.29, 38.0, ..., 339.0, 2.7042, '<1H OCEAN'],\n",
       "       [-121.93, 37.05, 14.0, ..., 113.0, 6.4214, '<1H OCEAN'],\n",
       "       [-117.2, 32.77, 31.0, ..., 462.0, 2.8621, 'NEAR OCEAN'],\n",
       "       ...,\n",
       "       [-116.4, 34.09, 9.0, ..., 765.0, 3.2723, 'INLAND'],\n",
       "       [-118.01, 33.82, 31.0, ..., 356.0, 4.0625, '<1H OCEAN'],\n",
       "       [-122.45, 37.77, 52.0, ..., 639.0, 3.575, 'NEAR BAY']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "housing_extra_attribs = attr_adder.transform(housing.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# housing_extra_attribs\n",
    "housing_extra_attribs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
       "       'total_bedrooms', 'population', 'households', 'median_income',\n",
       "       'ocean_proximity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([17606, 18632, 14650,  3230,  3555, 19480,  8879, 13685,  4937,\n",
       "             4861,\n",
       "            ...\n",
       "            15270,  3754, 12166,  6003,  7364,  6563, 12053, 13908, 11159,\n",
       "            15775],\n",
       "           dtype='int64', length=16512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity</th>\n",
       "      <th>rooms_per_household</th>\n",
       "      <th>population_per_household</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17606</th>\n",
       "      <td>-121.89</td>\n",
       "      <td>37.29</td>\n",
       "      <td>38</td>\n",
       "      <td>1568</td>\n",
       "      <td>351</td>\n",
       "      <td>710</td>\n",
       "      <td>339</td>\n",
       "      <td>2.7042</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>4.62537</td>\n",
       "      <td>2.0944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18632</th>\n",
       "      <td>-121.93</td>\n",
       "      <td>37.05</td>\n",
       "      <td>14</td>\n",
       "      <td>679</td>\n",
       "      <td>108</td>\n",
       "      <td>306</td>\n",
       "      <td>113</td>\n",
       "      <td>6.4214</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>6.00885</td>\n",
       "      <td>2.70796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14650</th>\n",
       "      <td>-117.2</td>\n",
       "      <td>32.77</td>\n",
       "      <td>31</td>\n",
       "      <td>1952</td>\n",
       "      <td>471</td>\n",
       "      <td>936</td>\n",
       "      <td>462</td>\n",
       "      <td>2.8621</td>\n",
       "      <td>NEAR OCEAN</td>\n",
       "      <td>4.22511</td>\n",
       "      <td>2.02597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>-119.61</td>\n",
       "      <td>36.31</td>\n",
       "      <td>25</td>\n",
       "      <td>1847</td>\n",
       "      <td>371</td>\n",
       "      <td>1460</td>\n",
       "      <td>353</td>\n",
       "      <td>1.8839</td>\n",
       "      <td>INLAND</td>\n",
       "      <td>5.23229</td>\n",
       "      <td>4.13598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3555</th>\n",
       "      <td>-118.59</td>\n",
       "      <td>34.23</td>\n",
       "      <td>17</td>\n",
       "      <td>6592</td>\n",
       "      <td>1525</td>\n",
       "      <td>4459</td>\n",
       "      <td>1463</td>\n",
       "      <td>3.0347</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>4.50581</td>\n",
       "      <td>3.04785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      longitude latitude housing_median_age total_rooms total_bedrooms  \\\n",
       "17606   -121.89    37.29                 38        1568            351   \n",
       "18632   -121.93    37.05                 14         679            108   \n",
       "14650    -117.2    32.77                 31        1952            471   \n",
       "3230    -119.61    36.31                 25        1847            371   \n",
       "3555    -118.59    34.23                 17        6592           1525   \n",
       "\n",
       "      population households median_income ocean_proximity rooms_per_household  \\\n",
       "17606        710        339        2.7042       <1H OCEAN             4.62537   \n",
       "18632        306        113        6.4214       <1H OCEAN             6.00885   \n",
       "14650        936        462        2.8621      NEAR OCEAN             4.22511   \n",
       "3230        1460        353        1.8839          INLAND             5.23229   \n",
       "3555        4459       1463        3.0347       <1H OCEAN             4.50581   \n",
       "\n",
       "      population_per_household  \n",
       "17606                   2.0944  \n",
       "18632                  2.70796  \n",
       "14650                  2.02597  \n",
       "3230                   4.13598  \n",
       "3555                   3.04785  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_extra_attribs = pd.DataFrame(\n",
    "    housing_extra_attribs,\n",
    "    columns=list(housing.columns) + [\"rooms_per_household\", \"population_per_household\"],\n",
    "    index=housing.index)\n",
    "housing_extra_attribs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 转换流水线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[from sklearn.pipeline import Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html?highlight=pipeline#sklearn.pipeline.Pipeline.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('attribs_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pipeline设置流程\n",
    "    1. 中位数填充\n",
    "    2. 特征加入\n",
    "    3. 将数据标准化（特征缩放）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同比例缩放所有属性，常用的两种方法是:最小-最大缩放和标 准化。\n",
    "1. 最小-最大缩放(又叫作归一化)很简单:将值重新缩放使其最终范围归于0到1之间。实现方法是将值减去最小值并除以最大值和最小值的差。对此，Scikit-Learn提供了一个名为MinMaxScaler的转换器。如果出于某种原因，你希望范围不是0~1，你可以通过调整超参数feature_range进行更改。\n",
    "2. 标准化则完全不一样:首先减去平均值(所以标准化值的均值总是零)，然后除以方差，从而使得结果的分布具备单位方差。不同于最小-最大缩放的是，标准化不将值绑定到特定范围，对某些算法而言，这可能是个问题(例如，神经网络期望的输入值范围通常是0到1)。但是标准化的方法受异常值的影响更小。例如，假设某个地区的平均收入等于100(错误数据)。最小-最大缩放会将所有其他值从0-15降到0-0.15，而标准化则不会受到很大影响。Scikit-Learn提供了一个标准化的转换器StandadScaler。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num_tr = num_pipeline.fit_transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.15604281,  0.77194962,  0.74333089, -0.49323393, -0.44543821,\n",
       "       -0.63621141, -0.42069842, -0.61493744, -0.31205452, -0.08649871,\n",
       "        0.15531753])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_num_tr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_std = pd.DataFrame(\n",
    "    housing_num_tr,\n",
    "    columns=list(housing.columns) + [\"rooms_per_household\", \"population_per_household\"],\n",
    "    index=housing.index)\n",
    "#housing_std.hist(bins=50, figsize=(15,15));\n",
    "# 均值为0\n",
    "# 上述语句后面加分号会使下面的地址不显示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将文本数据进行one-hot编码（密集数组）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.15604281,  0.77194962,  0.74333089, -0.49323393, -0.44543821,\n",
       "       -0.63621141, -0.42069842, -0.61493744, -0.31205452, -0.08649871,\n",
       "        0.15531753,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_prepared[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16512, 16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Create a class to select numerical or categorical columns \n",
    "class OldDataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OldDataFrameSelector(attribute_names='longitude')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_attribs = list(housing_num)\n",
    "# OldDataFrameSelector(num_attribs)\n",
    "OldDataFrameSelector('longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "old_num_pipeline = Pipeline([\n",
    "        ('selector', OldDataFrameSelector(num_attribs)),\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attribs_adder', CombinedAttributesAdder()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "old_cat_pipeline = Pipeline([\n",
    "        ('selector', OldDataFrameSelector(cat_attribs)),\n",
    "        ('cat_encoder', OneHotEncoder(sparse=False)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sklearn提供了FeatureUnion()实现上述的ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "old_full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", old_num_pipeline),\n",
    "        (\"cat_pipeline\", old_cat_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.15604281,  0.77194962,  0.74333089, -0.49323393, -0.44543821,\n",
       "       -0.63621141, -0.42069842, -0.61493744, -0.31205452, -0.08649871,\n",
       "        0.15531753,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_housing_prepared = old_full_pipeline.fit_transform(housing)\n",
    "old_housing_prepared[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(housing_prepared, old_housing_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68628.19819848923"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "housing_predictions = lin_reg.predict(housing_prepared)\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49439.89599001897"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "lin_mae = mean_absolute_error(housing_labels, housing_predictions)\n",
    "lin_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=42, splitter='best')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_predictions = tree_reg.predict(housing_prepared)\n",
    "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交叉验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [70194.33680785 66855.16363941 72432.58244769 70758.73896782\n",
      " 71115.88230639 75585.14172901 70262.86139133 70273.6325285\n",
      " 75366.87952553 71231.65726027]\n",
      "Mean: 71407.68766037929\n",
      "Standard deviation: 2439.4345041191004\n"
     ]
    }
   ],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#dd00dd\"> Scikit-Learn的交叉验证功能更倾向于使用效用函数(越大越好)而不是成本函数(越小越好)，所以计算分数的函数实际上是负的MSE(一个负值)函数，这就是为什么上面的代码在计算平方根之 前会先计算出-scores。 </font><br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [66782.73843989 66960.118071   70347.95244419 74739.57052552\n",
      " 68031.13388938 71193.84183426 64969.63056405 68281.61137997\n",
      " 71552.91566558 67665.10082067]\n",
      "Mean: 69052.46136345083\n",
      "Standard deviation: 2731.6740017983498\n"
     ]
    }
   ],
   "source": [
    "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "forest_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18603.515021376355"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_predictions = forest_reg.predict(housing_prepared)\n",
    "forest_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [49519.80364233 47461.9115823  50029.02762854 52325.28068953\n",
      " 49308.39426421 53446.37892622 48634.8036574  47585.73832311\n",
      " 53490.10699751 50021.5852922 ]\n",
      "Mean: 50182.303100336096\n",
      "Standard deviation: 2097.0810550985693\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       10.000000\n",
       "mean     69052.461363\n",
       "std       2879.437224\n",
       "min      64969.630564\n",
       "25%      67136.363758\n",
       "50%      68156.372635\n",
       "75%      70982.369487\n",
       "max      74739.570526\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(lin_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "pd.Series(np.sqrt(-scores)).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111094.6308539982"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_reg = SVR(kernel=\"linear\")\n",
    "svm_reg.fit(housing_prepared, housing_labels)\n",
    "housing_predictions = svm_reg.predict(housing_prepared)\n",
    "svm_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "svm_rmse = np.sqrt(svm_mse)\n",
    "svm_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型微调"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网格搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 你所要做的只是告诉它你要进行实验的超参数是什么，以及需要尝试的值，它将会使用交叉验证来评估超参数值的所有可能的组合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=42,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'max_features': [2, 4, 6, 8],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "grid_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以查看获得的最佳参数组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 8, 'n_estimators': 30}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features=8, max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=30, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可以直接得到最好的估算器（因为被评估的n_estimator最大值是30，你还可以试试更高的值，评分可能还会继续改善。）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取超参数组合的评估分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63669.11631261028 {'max_features': 2, 'n_estimators': 3}\n",
      "55627.099719926795 {'max_features': 2, 'n_estimators': 10}\n",
      "53384.57275149205 {'max_features': 2, 'n_estimators': 30}\n",
      "60965.950449450494 {'max_features': 4, 'n_estimators': 3}\n",
      "52741.04704299915 {'max_features': 4, 'n_estimators': 10}\n",
      "50377.40461678399 {'max_features': 4, 'n_estimators': 30}\n",
      "58663.93866579625 {'max_features': 6, 'n_estimators': 3}\n",
      "52006.19873526564 {'max_features': 6, 'n_estimators': 10}\n",
      "50146.51167415009 {'max_features': 6, 'n_estimators': 30}\n",
      "57869.25276169646 {'max_features': 8, 'n_estimators': 3}\n",
      "51711.127883959234 {'max_features': 8, 'n_estimators': 10}\n",
      "49682.273345071546 {'max_features': 8, 'n_estimators': 30}\n",
      "62895.06951262424 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "54658.176157539405 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "59470.40652318466 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "52724.9822587892 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "57490.5691951261 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "51009.495668875716 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050248</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 3}</td>\n",
       "      <td>-3.837622e+09</td>\n",
       "      <td>-4.147108e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.053756e+09</td>\n",
       "      <td>1.519591e+08</td>\n",
       "      <td>18</td>\n",
       "      <td>-1.064113e+09</td>\n",
       "      <td>-1.105142e+09</td>\n",
       "      <td>-1.116550e+09</td>\n",
       "      <td>-1.112342e+09</td>\n",
       "      <td>-1.129650e+09</td>\n",
       "      <td>-1.105559e+09</td>\n",
       "      <td>2.220402e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.157920</td>\n",
       "      <td>0.007347</td>\n",
       "      <td>0.008690</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 10}</td>\n",
       "      <td>-3.047771e+09</td>\n",
       "      <td>-3.254861e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.094374e+09</td>\n",
       "      <td>1.327062e+08</td>\n",
       "      <td>11</td>\n",
       "      <td>-5.927175e+08</td>\n",
       "      <td>-5.870952e+08</td>\n",
       "      <td>-5.776964e+08</td>\n",
       "      <td>-5.716332e+08</td>\n",
       "      <td>-5.802501e+08</td>\n",
       "      <td>-5.818785e+08</td>\n",
       "      <td>7.345821e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.483710</td>\n",
       "      <td>0.024106</td>\n",
       "      <td>0.023099</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 2, 'n_estimators': 30}</td>\n",
       "      <td>-2.689185e+09</td>\n",
       "      <td>-3.021086e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.849913e+09</td>\n",
       "      <td>1.626875e+08</td>\n",
       "      <td>9</td>\n",
       "      <td>-4.381089e+08</td>\n",
       "      <td>-4.391272e+08</td>\n",
       "      <td>-4.371702e+08</td>\n",
       "      <td>-4.376955e+08</td>\n",
       "      <td>-4.452654e+08</td>\n",
       "      <td>-4.394734e+08</td>\n",
       "      <td>2.966320e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.010926</td>\n",
       "      <td>0.003284</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 3}</td>\n",
       "      <td>-3.730181e+09</td>\n",
       "      <td>-3.786886e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.716847e+09</td>\n",
       "      <td>1.631510e+08</td>\n",
       "      <td>16</td>\n",
       "      <td>-9.865163e+08</td>\n",
       "      <td>-1.012565e+09</td>\n",
       "      <td>-9.169425e+08</td>\n",
       "      <td>-1.037400e+09</td>\n",
       "      <td>-9.707739e+08</td>\n",
       "      <td>-9.848396e+08</td>\n",
       "      <td>4.084607e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.267336</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.008162</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 10}</td>\n",
       "      <td>-2.666283e+09</td>\n",
       "      <td>-2.784511e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.781618e+09</td>\n",
       "      <td>1.268607e+08</td>\n",
       "      <td>8</td>\n",
       "      <td>-5.097115e+08</td>\n",
       "      <td>-5.162820e+08</td>\n",
       "      <td>-4.962893e+08</td>\n",
       "      <td>-5.436192e+08</td>\n",
       "      <td>-5.160297e+08</td>\n",
       "      <td>-5.163863e+08</td>\n",
       "      <td>1.542862e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.759820</td>\n",
       "      <td>0.013053</td>\n",
       "      <td>0.021953</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 4, 'n_estimators': 30}</td>\n",
       "      <td>-2.387153e+09</td>\n",
       "      <td>-2.588448e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.537883e+09</td>\n",
       "      <td>1.214614e+08</td>\n",
       "      <td>3</td>\n",
       "      <td>-3.838835e+08</td>\n",
       "      <td>-3.880268e+08</td>\n",
       "      <td>-3.790867e+08</td>\n",
       "      <td>-4.040957e+08</td>\n",
       "      <td>-3.845520e+08</td>\n",
       "      <td>-3.879289e+08</td>\n",
       "      <td>8.571233e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.105190</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 3}</td>\n",
       "      <td>-3.119657e+09</td>\n",
       "      <td>-3.586319e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.441458e+09</td>\n",
       "      <td>1.893056e+08</td>\n",
       "      <td>14</td>\n",
       "      <td>-9.245343e+08</td>\n",
       "      <td>-8.886939e+08</td>\n",
       "      <td>-9.353135e+08</td>\n",
       "      <td>-9.009801e+08</td>\n",
       "      <td>-8.624664e+08</td>\n",
       "      <td>-9.023976e+08</td>\n",
       "      <td>2.591445e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.346112</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.008140</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 10}</td>\n",
       "      <td>-2.549663e+09</td>\n",
       "      <td>-2.782039e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.704645e+09</td>\n",
       "      <td>1.471569e+08</td>\n",
       "      <td>6</td>\n",
       "      <td>-4.980344e+08</td>\n",
       "      <td>-5.045869e+08</td>\n",
       "      <td>-4.994664e+08</td>\n",
       "      <td>-4.990325e+08</td>\n",
       "      <td>-5.055542e+08</td>\n",
       "      <td>-5.013349e+08</td>\n",
       "      <td>3.100456e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.064220</td>\n",
       "      <td>0.026476</td>\n",
       "      <td>0.021468</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 6, 'n_estimators': 30}</td>\n",
       "      <td>-2.370010e+09</td>\n",
       "      <td>-2.583638e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.514673e+09</td>\n",
       "      <td>1.285080e+08</td>\n",
       "      <td>2</td>\n",
       "      <td>-3.838538e+08</td>\n",
       "      <td>-3.804711e+08</td>\n",
       "      <td>-3.805218e+08</td>\n",
       "      <td>-3.856095e+08</td>\n",
       "      <td>-3.901917e+08</td>\n",
       "      <td>-3.841296e+08</td>\n",
       "      <td>3.617057e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.130284</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 3}</td>\n",
       "      <td>-3.353504e+09</td>\n",
       "      <td>-3.348552e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.348850e+09</td>\n",
       "      <td>1.241939e+08</td>\n",
       "      <td>13</td>\n",
       "      <td>-9.228123e+08</td>\n",
       "      <td>-8.553031e+08</td>\n",
       "      <td>-8.603321e+08</td>\n",
       "      <td>-8.881964e+08</td>\n",
       "      <td>-9.151287e+08</td>\n",
       "      <td>-8.883545e+08</td>\n",
       "      <td>2.750227e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.438163</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.008087</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 10}</td>\n",
       "      <td>-2.571970e+09</td>\n",
       "      <td>-2.718994e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.674041e+09</td>\n",
       "      <td>1.392777e+08</td>\n",
       "      <td>5</td>\n",
       "      <td>-4.932416e+08</td>\n",
       "      <td>-4.815238e+08</td>\n",
       "      <td>-4.730979e+08</td>\n",
       "      <td>-5.155367e+08</td>\n",
       "      <td>-4.985555e+08</td>\n",
       "      <td>-4.923911e+08</td>\n",
       "      <td>1.459294e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.418862</td>\n",
       "      <td>0.027502</td>\n",
       "      <td>0.022475</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_features': 8, 'n_estimators': 30}</td>\n",
       "      <td>-2.357390e+09</td>\n",
       "      <td>-2.546640e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.468328e+09</td>\n",
       "      <td>1.091662e+08</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.841658e+08</td>\n",
       "      <td>-3.744500e+08</td>\n",
       "      <td>-3.773239e+08</td>\n",
       "      <td>-3.882250e+08</td>\n",
       "      <td>-3.810005e+08</td>\n",
       "      <td>-3.810330e+08</td>\n",
       "      <td>4.871017e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.078063</td>\n",
       "      <td>0.004407</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 2, 'n_est...</td>\n",
       "      <td>-3.785816e+09</td>\n",
       "      <td>-4.166012e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.955790e+09</td>\n",
       "      <td>1.900964e+08</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.251734</td>\n",
       "      <td>0.009785</td>\n",
       "      <td>0.009787</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 2, 'n_est...</td>\n",
       "      <td>-2.810721e+09</td>\n",
       "      <td>-3.107789e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.987516e+09</td>\n",
       "      <td>1.539234e+08</td>\n",
       "      <td>10</td>\n",
       "      <td>-6.056477e-02</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-2.967449e+00</td>\n",
       "      <td>-6.056027e-01</td>\n",
       "      <td>1.181156e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.103330</td>\n",
       "      <td>0.008533</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 3, 'n_est...</td>\n",
       "      <td>-3.618324e+09</td>\n",
       "      <td>-3.441527e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.536729e+09</td>\n",
       "      <td>7.795057e+07</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-6.072840e+01</td>\n",
       "      <td>-1.214568e+01</td>\n",
       "      <td>2.429136e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.347838</td>\n",
       "      <td>0.016820</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 3, 'n_est...</td>\n",
       "      <td>-2.757999e+09</td>\n",
       "      <td>-2.851737e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.779924e+09</td>\n",
       "      <td>6.286720e+07</td>\n",
       "      <td>7</td>\n",
       "      <td>-2.089484e+01</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-5.465556e+00</td>\n",
       "      <td>-5.272080e+00</td>\n",
       "      <td>8.093117e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.128603</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>0.003930</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 4, 'n_est...</td>\n",
       "      <td>-3.134040e+09</td>\n",
       "      <td>-3.559375e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.305166e+09</td>\n",
       "      <td>1.879165e+08</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.436932</td>\n",
       "      <td>0.016362</td>\n",
       "      <td>0.010034</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>{'bootstrap': False, 'max_features': 4, 'n_est...</td>\n",
       "      <td>-2.525578e+09</td>\n",
       "      <td>-2.710011e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.601969e+09</td>\n",
       "      <td>1.088048e+08</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-1.514119e-02</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-3.028238e-03</td>\n",
       "      <td>6.056477e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.050248      0.003803         0.002867        0.000184   \n",
       "1        0.157920      0.007347         0.008690        0.001243   \n",
       "2        0.483710      0.024106         0.023099        0.002196   \n",
       "3        0.084279      0.010926         0.003284        0.000464   \n",
       "4        0.267336      0.014000         0.008162        0.000318   \n",
       "5        0.759820      0.013053         0.021953        0.000734   \n",
       "6        0.105190      0.002834         0.002890        0.000236   \n",
       "7        0.346112      0.005124         0.008140        0.000677   \n",
       "8        1.064220      0.026476         0.021468        0.000738   \n",
       "9        0.130284      0.002023         0.002863        0.000131   \n",
       "10       0.438163      0.004677         0.008087        0.000461   \n",
       "11       1.418862      0.027502         0.022475        0.001328   \n",
       "12       0.078063      0.004407         0.003900        0.000640   \n",
       "13       0.251734      0.009785         0.009787        0.000425   \n",
       "14       0.103330      0.008533         0.003653        0.000413   \n",
       "15       0.347838      0.016820         0.010009        0.000844   \n",
       "16       0.128603      0.003387         0.003930        0.000472   \n",
       "17       0.436932      0.016362         0.010034        0.000775   \n",
       "\n",
       "   param_max_features param_n_estimators param_bootstrap  \\\n",
       "0                   2                  3             NaN   \n",
       "1                   2                 10             NaN   \n",
       "2                   2                 30             NaN   \n",
       "3                   4                  3             NaN   \n",
       "4                   4                 10             NaN   \n",
       "5                   4                 30             NaN   \n",
       "6                   6                  3             NaN   \n",
       "7                   6                 10             NaN   \n",
       "8                   6                 30             NaN   \n",
       "9                   8                  3             NaN   \n",
       "10                  8                 10             NaN   \n",
       "11                  8                 30             NaN   \n",
       "12                  2                  3           False   \n",
       "13                  2                 10           False   \n",
       "14                  3                  3           False   \n",
       "15                  3                 10           False   \n",
       "16                  4                  3           False   \n",
       "17                  4                 10           False   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0              {'max_features': 2, 'n_estimators': 3}      -3.837622e+09   \n",
       "1             {'max_features': 2, 'n_estimators': 10}      -3.047771e+09   \n",
       "2             {'max_features': 2, 'n_estimators': 30}      -2.689185e+09   \n",
       "3              {'max_features': 4, 'n_estimators': 3}      -3.730181e+09   \n",
       "4             {'max_features': 4, 'n_estimators': 10}      -2.666283e+09   \n",
       "5             {'max_features': 4, 'n_estimators': 30}      -2.387153e+09   \n",
       "6              {'max_features': 6, 'n_estimators': 3}      -3.119657e+09   \n",
       "7             {'max_features': 6, 'n_estimators': 10}      -2.549663e+09   \n",
       "8             {'max_features': 6, 'n_estimators': 30}      -2.370010e+09   \n",
       "9              {'max_features': 8, 'n_estimators': 3}      -3.353504e+09   \n",
       "10            {'max_features': 8, 'n_estimators': 10}      -2.571970e+09   \n",
       "11            {'max_features': 8, 'n_estimators': 30}      -2.357390e+09   \n",
       "12  {'bootstrap': False, 'max_features': 2, 'n_est...      -3.785816e+09   \n",
       "13  {'bootstrap': False, 'max_features': 2, 'n_est...      -2.810721e+09   \n",
       "14  {'bootstrap': False, 'max_features': 3, 'n_est...      -3.618324e+09   \n",
       "15  {'bootstrap': False, 'max_features': 3, 'n_est...      -2.757999e+09   \n",
       "16  {'bootstrap': False, 'max_features': 4, 'n_est...      -3.134040e+09   \n",
       "17  {'bootstrap': False, 'max_features': 4, 'n_est...      -2.525578e+09   \n",
       "\n",
       "    split1_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0       -4.147108e+09  ...    -4.053756e+09    1.519591e+08               18   \n",
       "1       -3.254861e+09  ...    -3.094374e+09    1.327062e+08               11   \n",
       "2       -3.021086e+09  ...    -2.849913e+09    1.626875e+08                9   \n",
       "3       -3.786886e+09  ...    -3.716847e+09    1.631510e+08               16   \n",
       "4       -2.784511e+09  ...    -2.781618e+09    1.268607e+08                8   \n",
       "5       -2.588448e+09  ...    -2.537883e+09    1.214614e+08                3   \n",
       "6       -3.586319e+09  ...    -3.441458e+09    1.893056e+08               14   \n",
       "7       -2.782039e+09  ...    -2.704645e+09    1.471569e+08                6   \n",
       "8       -2.583638e+09  ...    -2.514673e+09    1.285080e+08                2   \n",
       "9       -3.348552e+09  ...    -3.348850e+09    1.241939e+08               13   \n",
       "10      -2.718994e+09  ...    -2.674041e+09    1.392777e+08                5   \n",
       "11      -2.546640e+09  ...    -2.468328e+09    1.091662e+08                1   \n",
       "12      -4.166012e+09  ...    -3.955790e+09    1.900964e+08               17   \n",
       "13      -3.107789e+09  ...    -2.987516e+09    1.539234e+08               10   \n",
       "14      -3.441527e+09  ...    -3.536729e+09    7.795057e+07               15   \n",
       "15      -2.851737e+09  ...    -2.779924e+09    6.286720e+07                7   \n",
       "16      -3.559375e+09  ...    -3.305166e+09    1.879165e+08               12   \n",
       "17      -2.710011e+09  ...    -2.601969e+09    1.088048e+08                4   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0        -1.064113e+09       -1.105142e+09       -1.116550e+09   \n",
       "1        -5.927175e+08       -5.870952e+08       -5.776964e+08   \n",
       "2        -4.381089e+08       -4.391272e+08       -4.371702e+08   \n",
       "3        -9.865163e+08       -1.012565e+09       -9.169425e+08   \n",
       "4        -5.097115e+08       -5.162820e+08       -4.962893e+08   \n",
       "5        -3.838835e+08       -3.880268e+08       -3.790867e+08   \n",
       "6        -9.245343e+08       -8.886939e+08       -9.353135e+08   \n",
       "7        -4.980344e+08       -5.045869e+08       -4.994664e+08   \n",
       "8        -3.838538e+08       -3.804711e+08       -3.805218e+08   \n",
       "9        -9.228123e+08       -8.553031e+08       -8.603321e+08   \n",
       "10       -4.932416e+08       -4.815238e+08       -4.730979e+08   \n",
       "11       -3.841658e+08       -3.744500e+08       -3.773239e+08   \n",
       "12       -0.000000e+00       -0.000000e+00       -0.000000e+00   \n",
       "13       -6.056477e-02       -0.000000e+00       -0.000000e+00   \n",
       "14       -0.000000e+00       -0.000000e+00       -0.000000e+00   \n",
       "15       -2.089484e+01       -0.000000e+00       -0.000000e+00   \n",
       "16       -0.000000e+00       -0.000000e+00       -0.000000e+00   \n",
       "17       -0.000000e+00       -1.514119e-02       -0.000000e+00   \n",
       "\n",
       "    split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0        -1.112342e+09       -1.129650e+09     -1.105559e+09     2.220402e+07  \n",
       "1        -5.716332e+08       -5.802501e+08     -5.818785e+08     7.345821e+06  \n",
       "2        -4.376955e+08       -4.452654e+08     -4.394734e+08     2.966320e+06  \n",
       "3        -1.037400e+09       -9.707739e+08     -9.848396e+08     4.084607e+07  \n",
       "4        -5.436192e+08       -5.160297e+08     -5.163863e+08     1.542862e+07  \n",
       "5        -4.040957e+08       -3.845520e+08     -3.879289e+08     8.571233e+06  \n",
       "6        -9.009801e+08       -8.624664e+08     -9.023976e+08     2.591445e+07  \n",
       "7        -4.990325e+08       -5.055542e+08     -5.013349e+08     3.100456e+06  \n",
       "8        -3.856095e+08       -3.901917e+08     -3.841296e+08     3.617057e+06  \n",
       "9        -8.881964e+08       -9.151287e+08     -8.883545e+08     2.750227e+07  \n",
       "10       -5.155367e+08       -4.985555e+08     -4.923911e+08     1.459294e+07  \n",
       "11       -3.882250e+08       -3.810005e+08     -3.810330e+08     4.871017e+06  \n",
       "12       -0.000000e+00       -0.000000e+00      0.000000e+00     0.000000e+00  \n",
       "13       -0.000000e+00       -2.967449e+00     -6.056027e-01     1.181156e+00  \n",
       "14       -0.000000e+00       -6.072840e+01     -1.214568e+01     2.429136e+01  \n",
       "15       -0.000000e+00       -5.465556e+00     -5.272080e+00     8.093117e+00  \n",
       "16       -0.000000e+00       -0.000000e+00      0.000000e+00     0.000000e+00  \n",
       "17       -0.000000e+00       -0.000000e+00     -3.028238e-03     6.056477e-03  \n",
       "\n",
       "[18 rows x 23 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果探索的组合数量较少——例如上一个示例，网格搜索是一个不错的方法;但是当超参数的搜索范围(search space)较大时，通常会优先选择使用RandomizedSearchCV。这个类用起来与GridSearchCV 类大致相同，但它不会尝试所有可能的组合，而是在每次迭代中为每个超参数选择一个随机值，然后对一定数量的随机组合进行评估。这个方法有两个显著特性:\n",
    "1. 如果运行随机搜索1000个迭代，那么将会探索每个超参数的1000个不同的值(而不是像网格搜索方法那样每个超参数仅探索少量几个值)。\n",
    "2. 通过简单地设置迭代次数，可以更好地控制要分配给探索的超参数的计算预算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   ccp_alpha=0.0,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   max_samples=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=100,\n",
       "                                                   n_jobs=None, oob_score=Fals...\n",
       "                                                   warm_start=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1a1eb59390>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1a1eb59b90>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring='neg_mean_squared_error',\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=8),\n",
    "    }\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "rnd_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49150.70756927707 {'max_features': 7, 'n_estimators': 180}\n",
      "51389.889203389284 {'max_features': 5, 'n_estimators': 15}\n",
      "50796.155224308866 {'max_features': 3, 'n_estimators': 72}\n",
      "50835.13360315349 {'max_features': 5, 'n_estimators': 21}\n",
      "49280.9449827171 {'max_features': 7, 'n_estimators': 122}\n",
      "50774.90662363929 {'max_features': 3, 'n_estimators': 75}\n",
      "50682.78888164288 {'max_features': 3, 'n_estimators': 88}\n",
      "49608.99608105296 {'max_features': 5, 'n_estimators': 100}\n",
      "50473.61930350219 {'max_features': 3, 'n_estimators': 150}\n",
      "64429.84143294435 {'max_features': 5, 'n_estimators': 2}\n"
     ]
    }
   ],
   "source": [
    "cvres = rnd_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.33442355e-02, 6.29090705e-02, 4.11437985e-02, 1.46726854e-02,\n",
       "       1.41064835e-02, 1.48742809e-02, 1.42575993e-02, 3.66158981e-01,\n",
       "       5.64191792e-02, 1.08792957e-01, 5.33510773e-02, 1.03114883e-02,\n",
       "       1.64780994e-01, 6.02803867e-05, 1.96041560e-03, 2.85647464e-03])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 集成方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 还有一种微调系统的方法是将表现最优的模型组合起来。组合 (或“集成”)方法通常比最佳的单一模型更好(就像随机森林比其所 依赖的任何单个决策树模型更好一样)，特别是当单一模型会产生严 重不同类型的错误时更是如此。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过测试集评估系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5241</th>\n",
       "      <td>-118.39</td>\n",
       "      <td>34.12</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6447.0</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>2184.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>8.2816</td>\n",
       "      <td>500001.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10970</th>\n",
       "      <td>-117.86</td>\n",
       "      <td>33.77</td>\n",
       "      <td>39.0</td>\n",
       "      <td>4159.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>1669.0</td>\n",
       "      <td>651.0</td>\n",
       "      <td>4.6111</td>\n",
       "      <td>240300.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20351</th>\n",
       "      <td>-119.05</td>\n",
       "      <td>34.21</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4357.0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>876.0</td>\n",
       "      <td>3.0119</td>\n",
       "      <td>218200.0</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6568</th>\n",
       "      <td>-118.15</td>\n",
       "      <td>34.20</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>4.1518</td>\n",
       "      <td>182100.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13285</th>\n",
       "      <td>-117.68</td>\n",
       "      <td>34.07</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1775.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>1067.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>4.0375</td>\n",
       "      <td>121300.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "5241     -118.39     34.12                29.0       6447.0          1012.0   \n",
       "10970    -117.86     33.77                39.0       4159.0           655.0   \n",
       "20351    -119.05     34.21                27.0       4357.0           926.0   \n",
       "6568     -118.15     34.20                52.0       1786.0           306.0   \n",
       "13285    -117.68     34.07                32.0       1775.0           314.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \\\n",
       "5241       2184.0       960.0         8.2816            500001.0   \n",
       "10970      1669.0       651.0         4.6111            240300.0   \n",
       "20351      2110.0       876.0         3.0119            218200.0   \n",
       "6568       1018.0       322.0         4.1518            182100.0   \n",
       "13285      1067.0       302.0         4.0375            121300.0   \n",
       "\n",
       "      ocean_proximity  \n",
       "5241        <1H OCEAN  \n",
       "10970       <1H OCEAN  \n",
       "20351       <1H OCEAN  \n",
       "6568           INLAND  \n",
       "13285          INLAND  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_test_set = pd.read_csv('./strat_test_set.csv', index_col=0)\n",
    "strat_test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.36615898061813423, 'median_income'),\n",
       " (0.16478099356159054, 'INLAND'),\n",
       " (0.10879295677551575, 'pop_per_hhold'),\n",
       " (0.07334423551601243, 'longitude'),\n",
       " (0.06290907048262032, 'latitude'),\n",
       " (0.056419179181954014, 'rooms_per_hhold'),\n",
       " (0.053351077347675815, 'bedrooms_per_room'),\n",
       " (0.04114379847872964, 'housing_median_age'),\n",
       " (0.014874280890402769, 'population'),\n",
       " (0.014672685420543239, 'total_rooms'),\n",
       " (0.014257599323407808, 'households'),\n",
       " (0.014106483453584104, 'total_bedrooms'),\n",
       " (0.010311488326303788, '<1H OCEAN'),\n",
       " (0.0028564746373201584, 'NEAR OCEAN'),\n",
       " (0.0019604155994780706, 'NEAR BAY'),\n",
       " (6.0280386727366e-05, 'ISLAND')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
    "#cat_encoder = cat_pipeline.named_steps[\"cat_encoder\"] # old solution\n",
    "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47730.22690385927"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 假设检验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 置信区间为95%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[T-Score vs. Z-Score: What’s the Difference?](https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/hypothesis-testing/t-score-vs-z-score/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4128,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "confidence = 0.95\n",
    "squared_errors = (final_predictions - y_test) ** 2\n",
    "squared_errors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先计算方差的置信区间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[stats.t](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.t.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2087128792.158995, 2469220328.428762)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.t.interval(confidence, len(squared_errors)-1,\n",
    "                 loc=squared_errors.mean(),\n",
    "                 scale=stats.sem(squared_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45685.10470776, 49691.25001878])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
    "                         loc=squared_errors.mean(),\n",
    "                         scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- t-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45685.10470776, 49691.25001877858)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = len(squared_errors)\n",
    "mean = squared_errors.mean()\n",
    "tscore = stats.t.ppf((1 + confidence) / 2, df=m - 1)\n",
    "tmargin = tscore * squared_errors.std(ddof=1) / np.sqrt(m)\n",
    "np.sqrt(mean - tmargin), np.sqrt(mean + tmargin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45685.717918136455, 49690.68623889413)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zscore = stats.norm.ppf((1 + confidence) / 2)\n",
    "zmargin = zscore * squared_errors.std(ddof=1) / np.sqrt(m)\n",
    "np.sqrt(mean - zmargin), np.sqrt(mean + zmargin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[pickle](https://docs.python.org/zh-cn/3/library/pickle.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "list_file = open('./housing_prepared.pickle', 'wb')\n",
    "pickle.dump(housing_prepared, list_file)\n",
    "list_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_file = open('./housing_labels.pickle', 'wb')\n",
    "pickle.dump(housing_labels, list_file)\n",
    "list_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "housing_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared.shspe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
